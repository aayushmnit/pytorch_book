{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf65eee",
   "metadata": {},
   "source": [
    "---\n",
    "title: Model pipeline with fastai's High-Level API \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04baa05",
   "metadata": {},
   "source": [
    "This section will cover the process of training a model for multi-class classification on MNIST data using the fastai high(application)-level API.  The image below illustrates the general steps involved in using the high-level API: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8cc7f7",
   "metadata": {},
   "source": [
    "<figure align = \"center\">\n",
    "    <img src=\"./img/fastai_highlevelflow.png\" style=\"width:100%\">\n",
    "    <figcaption align = \"center\">\n",
    "        Fig 10.1: Using fastai high-level API flow.\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c56843",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d4162",
   "metadata": {},
   "source": [
    "Download instruction can be found in [`Downloading Data from Kaggle`](8_NeuralNetworks.ipynb#downloading-data-from-kaggle) section of Modeling pipeline with Neural Networks chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc078f",
   "metadata": {},
   "source": [
    "## Creating DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26f39e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T19:29:26.490525Z",
     "start_time": "2023-04-23T19:29:26.487426Z"
    }
   },
   "source": [
    " First step in the process is creating a fastai `Dataloaders`. To begin, we will import the `fastai.vision` module, as we are working with image classification tasks in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652710b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T22:47:49.768994Z",
     "start_time": "2023-04-23T22:47:48.622432Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8692ec",
   "metadata": {},
   "source": [
    ":::{.callout-important collapse=false}\n",
    "It is generally not recommended to use `import *` in production scenarios. Instead, it is advisable to use precise imports. For instance, the function `ImageDataLoaders` is located in the [`fastai.vision`](https://github.com/fastai/fastai/blob/master/fastai/vision/data.py#L108) module, specifically in the `data.py` file. Therefore, the recommended import statement would be:\n",
    "```python\n",
    "from fastai.vision.data import ImageDataLoaders\n",
    "```\n",
    "\n",
    "This approach ensures that only the required function is imported, which is considered a good coding practice in production environments.\n",
    "\n",
    "For simplicity, we will stick with `import *` notion. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b37f1",
   "metadata": {},
   "source": [
    "Next, we will create our fastai `dataloaders` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b55048",
   "metadata": {},
   "source": [
    ":::{.callout-note collapse=false}\n",
    "It's important to note that fastai `DataLoaders` are not identical to PyTorch `dataloaders`. In fastai, many of the PyTorch classes are inherited and additional functionalities are added through a technique called [\"monkey-patching\"](https://en.wikipedia.org/wiki/Monkey_patch#:~:text=Monkey%20patching%20is%20a%20technique,Python%2C%20Groovy%2C%20etc.). This means that fastai extends the functionality of PyTorch classes by adding custom features and methods, providing a higher-level and more user-friendly API for deep learning tasks.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d411dd27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T22:47:53.858690Z",
     "start_time": "2023-04-23T22:47:50.453682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fastai.data.core.DataLoaders'>\n"
     ]
    }
   ],
   "source": [
    "dPath = Path(\"../data/mnist_png/\")\n",
    "dls = ImageDataLoaders.from_folder(\n",
    "        path = dPath, \n",
    "        train = \"training\", \n",
    "        valid_pct = 0.2,\n",
    "        seed=42,\n",
    "        img_cls = PILImageBW,\n",
    "        item_tfms=Resize(28),\n",
    "        batch_tfms=None,\n",
    "        bs=128\n",
    "    )\n",
    "print(type(dls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42afaf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T19:49:40.088741Z",
     "start_time": "2023-04-23T19:49:40.085552Z"
    }
   },
   "source": [
    "As evident from the code snippet above, it is possible to create a fastai `DataLoaders` in just one line of code. Let's delve into the details of what's happening with this function. The code above is creating a fastai `DataLoaders` object named `dls` using the `from_folder` method of `ImageDataLoaders` class. Here's a breakdown of the parameters being passed:\n",
    "\n",
    "- `path`: The path to the dataset folder is specified as `dPath`, which uses the fastai Path function. It's important to note that the Path function in fastai is a monkey-patched version of the standard [`pathlib.Path`](https://docs.python.org/3/library/pathlib.html) function in Python. \n",
    "- `train`: The name of the subfolder within the dataset folder that contains the training data, specified as \"training\".\n",
    "- `valid_pct`: The validation data percentage is set to 0.2 (20%), which means that the data will be randomly split into training and validation sets. Specifically, 80% of the data will be used for training, while 20% will be used for validation.\n",
    "- `seed`: The random seed used for reproducibility, specified as 42.\n",
    "- `img_cls`: The image class to be used is specified as [`PILImageBW`]((https://docs.fast.ai/vision.core.html#pilimagebw)), as the MNIST images are black and white single-channel images. `PILImageBW` is one of the general data types available in the [`vision.core`](https://docs.fast.ai/vision.core.html) module of the FastAI library.\n",
    "- `item_tfms`: The image transformation to be applied to each item, specified as Resize(28) which resizes the images to a size of 28x28 pixels. This operation is performed on CPU.\n",
    "- `batch_tfms`: The batch transformations to be applied, specified as None which means no batch transformations are applied.  `batch_tfms` is usually transforms performed on GPU.\n",
    "- `bs`: The batch size, specified as 128.\n",
    "\n",
    "Finally, the `type(dls)` statement is used to print the type of the dls object, which should be a fastai `DataLoaders` object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c08c1d",
   "metadata": {},
   "source": [
    "fastai offers various functions for easy inspection of data through data loaders. Let's use the `show_batch` function to visualize one batch of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994d4460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T22:47:55.264564Z",
     "start_time": "2023-04-23T22:47:53.883194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(figsize=(10,6)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb1678",
   "metadata": {},
   "source": [
    "It appears that we have successfully created a data loader with just one line of code. To better inspect the data, we can check the dimensions of a batch of data. Let's use the `one_batch` function on the `dls` data loader object to obtain a single batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97357a2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T22:47:56.298245Z",
     "start_time": "2023-04-23T22:47:55.289616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:torch.Size([128, 1, 28, 28]) \n",
      "Shape of Labels:torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "x,y = dls.one_batch()\n",
    "print(f'Shape of X:{x.shape} \\nShape of Labels:{y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e47f11",
   "metadata": {},
   "source": [
    "Upon inspection, we can observe that the input image batch has the following dimensions:\n",
    "\n",
    "- Batch size: 128\n",
    "- Number of channels: 1 (single channel)\n",
    "- Image height: 28\n",
    "- Image width: 28\n",
    "\n",
    "Additionally, the labels are represented as a vector of size 128, with one label per image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36e64c",
   "metadata": {},
   "source": [
    "## Creating a learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd6bd86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:35:06.960781Z",
     "start_time": "2023-04-23T20:35:06.946108Z"
    }
   },
   "source": [
    "The next step involves creating a fastai [`Learner`](https://docs.fast.ai/learner.html#learner) object using the [`vision_learner`](https://docs.fast.ai/vision.learner.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9aadcd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T22:47:56.449238Z",
     "start_time": "2023-04-23T22:47:56.346814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fastai.learner.Learner'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayush/miniconda3/envs/fastai/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/aayush/miniconda3/envs/fastai/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "learn = vision_learner(\n",
    "    dls=dls,  \n",
    "    arch= resnet18, \n",
    "    pretrained=False, \n",
    "    metrics=accuracy, \n",
    "    n_in=1\n",
    ")\n",
    "print(type(learn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56331a59",
   "metadata": {},
   "source": [
    "As evident from the code snippet above, it is possible to create a fastai `Learner` in just one line of code.  Let's delve into the details of what's happening with this function. The code above is creating a fastai `Learner` object for training a model on the MNIST dataset. Here's what each parameter in the vision_learner method does:\n",
    "\n",
    " - `dls`: This parameter specifies the data loaders object (dls) that we previously created for the dataset.\n",
    " - `arch`: The `arch` parameter specifies the neural network architecture to be used for training. In this case, we are using [resnet18](https://pytorch.org/vision/0.8/models.html) from `torchvision.models`, which is a popular convolutional neural network architecture. fastai models are PyTorch models, so they can accept any valid PyTorch model, whether it is custom-defined or sourced from the [`torchvision`](https://pytorch.org/vision/0.8/models.html) model hub or [`timm`](https://huggingface.co/docs/timm/) library, by simply specifying the model name. This allows for flexibility in choosing different neural network architectures for training, depending on the specific requirements of the task at hand.\n",
    " - `pretrained`: This parameter indicates whether to use pre-trained weights for the neural network. In this case, False means that we are not using any pre-trained weights. \n",
    " - `metrics`: This parameter specifies the evaluation metric(s) to be used during training. In this case, [`accuracy`](https://docs.fast.ai/metrics.html#accuracy) is used, which measures the classification accuracy. fastai provides other pre-implemented single-label classification metrics that you can use, and you can find them in the [metrics documentation](https://docs.fast.ai/metrics.html#single-label-classification).\n",
    " - `n_in` : This parameter specifies the number of input channels in the images. Since the MNIST images are grayscale with a single channel, n_in is set to 1.\n",
    " \n",
    "The `type(learn)` statement is then used to print the type of the `learn` object, which should be a fastai `Learner` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de6c5f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T21:16:57.379490Z",
     "start_time": "2023-04-23T21:16:57.359837Z"
    }
   },
   "source": [
    ":::{.callout-important collapse=false}\n",
    "The [`vision_learner`](https://docs.fast.ai/vision.learner.html#vision_learner) class in fastai comes with a lot of \"useful defaults\" that have been derived from training task in hand on various datasets. For instance, it automatically selects the `AdamW` optimizer as the default optimization function, sets the learning rate to `0.001` by default and loss function as [flattened CrossEntropyLoss](https://docs.fast.ai/losses.html#crossentropylossflat). You can refer to the [documentation of vision_learner](https://docs.fast.ai/vision.learner.html#vision_learner) to explore other default settings and configurations that may be useful for your specific task.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16ef3e90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T22:47:58.704047Z",
     "start_time": "2023-04-23T22:47:58.701225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer function used: <function Adam at 0x7f5d84437ca0>\n",
      "Default learning rate: 0.001\n",
      "Default loss function: FlattenedLoss of CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "print(f'Optimizer function used: {learn.opt_func}')\n",
    "print(f'Default learning rate: {learn.lr}')\n",
    "print(f'Default loss function: {learn.loss_func}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a59711f",
   "metadata": {},
   "source": [
    "fastai `Learner` class also comes with a lot of helpful functions. An example would be [`Learner.summary`](https://github.com/fastai/fastai/blob/master/fastai/callback/hook.py#L209) function which prints a summary of the model, optimizer and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a327187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T22:48:04.755866Z",
     "start_time": "2023-04-23T22:48:01.911298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Sequential (Input shape: 128 x 1 x 28 x 28)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     128 x 64 x 14 x 14  \n",
       "Conv2d                                    3136       True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     128 x 64 x 7 x 7    \n",
       "MaxPool2d                                                      \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     128 x 128 x 4 x 4   \n",
       "Conv2d                                    73728      True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    8192       True      \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     128 x 256 x 2 x 2   \n",
       "Conv2d                                    294912     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    32768      True      \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     128 x 512 x 1 x 1   \n",
       "Conv2d                                    1179648    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    131072     True      \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "AdaptiveAvgPool2d                                              \n",
       "AdaptiveMaxPool2d                                              \n",
       "____________________________________________________________________________\n",
       "                     128 x 1024          \n",
       "Flatten                                                        \n",
       "BatchNorm1d                               2048       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     128 x 512           \n",
       "Linear                                    524288     True      \n",
       "ReLU                                                           \n",
       "BatchNorm1d                               1024       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     128 x 10            \n",
       "Linear                                    5120       True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 11,702,720\n",
       "Total trainable params: 11,702,720\n",
       "Total non-trainable params: 0\n",
       "\n",
       "Optimizer used: <function Adam at 0x7f5d84437ca0>\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - CastToTensor\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690b32ab",
   "metadata": {},
   "source": [
    "The `Learner.summary` function provides a wealth of useful information, including:\n",
    "\n",
    "- Model layers and their trainable state\n",
    "- Total number of parameters in the model, as well as the number of trainable parameters\n",
    "- The optimizer used during training\n",
    "- The loss function employed\n",
    "- The [callbacks](https://docs.fast.ai/callback.core.html) used, which are special additional functions that run at various stages of training and inference. You can refer to the [documentation on callbacks](https://docs.fast.ai/callback.core.html)\n",
    "to learn more about them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f06af80",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f5643",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T21:52:26.285373Z",
     "start_time": "2023-04-23T21:52:26.269150Z"
    }
   },
   "source": [
    "fastai provides different `fit` functions in the `Learner` class that allow for flexible and convenient training of machine learning models. Here's an overview of some of the commonly used `fit` functions in Fastai:\n",
    "\n",
    "1. [`fit`](https://docs.fast.ai/learner.html#learner.fit): This is the most commonly used `fit` function in Fastai, which trains the model using stochastic gradient descent (SGD) or its variants. It allows you to specify the number of epochs, learning rate, weight decay, and other training parameters. You can also specify callbacks for custom behavior during training.\n",
    "\n",
    "2. [`fit_one_cycle`](https://docs.fast.ai/callback.schedule.html#learner.fit_one_cycle): This function implements the 1-cycle policy, a popular learning rate scheduling technique in deep learning. It automatically sets the learning rate, momentum, and weight decay to optimal values based on a predefined schedule. This can help improve the model's performance and speed up training.\n",
    "\n",
    "3. [`fit_sgdr`](https://docs.fast.ai/callback.schedule.html#learner.fit_sgdr): This function implements stochastic gradient descent with restarts (SGDR), a learning rate scheduling technique that periodically resets the learning rate to a smaller value during training. This helps the model escape from local minima and find better solutions.\n",
    "\n",
    "4. [`fit_flat_cos`](https://docs.fast.ai/callback.schedule.html#learner.fit_flat_cos): This function uses a cosine annealing learning rate schedule, where the learning rate is decreased gradually over time following a cosine curve. This helps the model converge to a better solution by avoiding overshooting.\n",
    "\n",
    "5. [`fine_tune`](https://docs.fast.ai/callback.schedule.html#learner.fine_tune): This function fine-tunes a pre-trained model by training only the last few layers while keeping the earlier layers frozen. This is useful for transfer learning, where you start with a pre-trained model and then fine-tune it on your specific task with limited data.\n",
    "\n",
    "These are some of the different `fit` functions available in Fastai's `Learner` class, providing flexibility and convenience for training machine learning models with various techniques and strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789b91ab",
   "metadata": {},
   "source": [
    "We will use `fit_one_cycle` function for our training example and train for five epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbdd15bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T22:52:03.922651Z",
     "start_time": "2023-04-23T22:48:08.185244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.164690</td>\n",
       "      <td>0.133020</td>\n",
       "      <td>0.962214</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.097386</td>\n",
       "      <td>0.152779</td>\n",
       "      <td>0.960214</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.059235</td>\n",
       "      <td>0.056804</td>\n",
       "      <td>0.982500</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.027329</td>\n",
       "      <td>0.030058</td>\n",
       "      <td>0.991500</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.023299</td>\n",
       "      <td>0.993071</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c372b01a",
   "metadata": {},
   "source": [
    "As we can see above, the `fit_one_cycle` function in fastai provides a progress bar(while training, not shown above) and displays statistics in a neat table after every epoch, which includes:\n",
    "\n",
    "- Train and validation loss\n",
    "- The defined metric, in this case `accuracy` on the validation set \n",
    "- Time taken to run that particular epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4706a70",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae669f",
   "metadata": {},
   "source": [
    "We can save the model weights, optimizer state and `DataLoaders` transform by using `export` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b1323",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "We will explore additional techniques for extracting model weights beyond what has been covered so far in later chapters.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a49f1855",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T23:06:33.278386Z",
     "start_time": "2023-04-23T23:06:33.101724Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.export(fname=\"mnist_highlevel.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8a6ee9",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9f8a99",
   "metadata": {},
   "source": [
    "To load the model we can use `load_learner` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc82bd6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T23:24:43.812001Z",
     "start_time": "2023-04-23T23:24:43.726410Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = load_learner(\n",
    "    fname=dPath/\"mnist_highlevel.pkl\", \n",
    "    cpu=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d34a9f",
   "metadata": {},
   "source": [
    "`load_learner` function takes following arguments - \n",
    "\n",
    "-  `fname` - The path of the saved learner object\n",
    "- `cpu` - This parameter is set to `True`, indicating that the learner object should be loaded onto the CPU for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dbf2c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T23:08:32.503293Z",
     "start_time": "2023-04-23T23:08:32.500114Z"
    }
   },
   "source": [
    "## Performing inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90618835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T23:13:27.544975Z",
     "start_time": "2023-04-23T23:13:27.541662Z"
    }
   },
   "source": [
    "To perform inference, we will first obtain the file path of an image from our testing folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7ea2ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T23:16:12.674645Z",
     "start_time": "2023-04-23T23:16:12.655918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample file path: ../data/mnist_png/testing/4/1010.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nNWOMUuCYRSFH5VIQUUKUsiCloZCp+Yg0oRasymKCvMPtNXu1lBTe1Njg+06BOHgLyhyi4gUkeKDUw2+H74fvEZrZ7n33Oce7oV/qcrXd9Hv1ypTAXbclQqmj99q00KzF57UmjNuVbq3YFXSQ8KY5Y50PmKptvRx4LsTSTkAwgDlHAweDYttBT9df5U02CvvRIGC5FUjAIQAqJeGWw0P8jPUzuxo+vRGlnbNOGRqNAnTNSY3APavcSkjSc2skw3hou/CQbgEXD25gxN16SXvZlxK2h7DFt6kRmLkAzcPU9Dru4PJO0nz1sBOfj6POQfASvf9KP7bwp/1A51FYNVx4nbZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = (dPath/\"testing/4\").ls()[0]\n",
    "print(f'Sample file path: {fname}')\n",
    "Image.open(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04959b",
   "metadata": {},
   "source": [
    "We have selected an image of the digit four from our test dataset. To perform inference we will use the [`predict`](https://docs.fast.ai/learner.html#learner.predict) method from `Learner` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "612a9602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T23:17:20.306028Z",
     "start_time": "2023-04-23T23:17:20.219794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('4', TensorBase(4), TensorBase([1.6044e-06, 2.5403e-06, 2.2100e-06, 2.8801e-07, 9.9986e-01,\n",
      "            4.1187e-07, 1.7771e-05, 2.4048e-05, 5.0337e-07, 9.5490e-05]))\n"
     ]
    }
   ],
   "source": [
    "preds = learn.predict(fname)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16923767",
   "metadata": {},
   "source": [
    "The prediction results include the following information:\n",
    "\n",
    "-  decoded model label: `4`. \n",
    "- The index with highest probability: `TensorBase(4)`. \n",
    "- Raw probabilities of each class in the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f00b1",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf89eed",
   "metadata": {},
   "source": [
    "In this chapter, we delved into the intricacies of building a model pipeline using `fastai`'s high-level API. We covered the essential steps of data preparation, model training, and inference, and demonstrated how the rich functionality of `fastai`'s high-level API can streamline these processes. We also explored the convenience of its abstractions for tasks like data augmentation, model selection, and model interpretation using the MNIST dataset as an example. In the next chapter, we will continue our journey by exploring similar concepts but with a focus on `fastai`'s mid-level API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
