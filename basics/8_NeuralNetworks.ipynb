{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b8fdc4",
   "metadata": {},
   "source": [
    "---\n",
    "title: Neural Networks (Draft)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7069c0",
   "metadata": {},
   "source": [
    "In previous chapters, we covered the fundamentals of PyTorch and applied it to a linear regression example. Now, we will expand on that knowledge by constructing neural networks using PyTorch. The dataset we will be utilizing is the `MNIST png` dataset from [Kaggle](https://www.kaggle.com/datasets/jidhumohan/mnist-png), as opposed to the CSV version, for a more practical experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89ff129",
   "metadata": {},
   "source": [
    "## Downloading Data from Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ce74d8",
   "metadata": {},
   "source": [
    "Here are few steps you need to perform before we download the data - \n",
    "\n",
    "- If you don’t have a Kaggle account, you can make one for free [here](https://www.kaggle.com/).\n",
    "- To download the dataset, you will need `kaggle` installed, you can run the following command in notebook or CLI.\n",
    "    ```{python}\n",
    "    !pip install kaggle >> /dev/null\n",
    "    ```\n",
    "- Have a `kaggle.json` stored in `~/.kaggle`. You can get your token by going to Your Profile -> Account -> Create New API Token.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42dc18",
   "metadata": {},
   "source": [
    "Once you have the above three steps done, run the API command provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84a29a4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T07:08:30.081823Z",
     "start_time": "2023-01-23T07:08:27.410023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading mnist-png.zip to ../data\n",
      " 87%|█████████████████████████████████     | 51.0M/58.6M [00:01<00:00, 33.4MB/s]\n",
      "100%|██████████████████████████████████████| 58.6M/58.6M [00:01<00:00, 33.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d jidhumohan/mnist-png -p \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a2ed36",
   "metadata": {},
   "source": [
    "To examine the file system, we will utilize the [fastcore](https://fastcore.fast.ai/) `Path` function. It enhances the functionality of python's `Path` class and simplifies the process of inspecting directories and folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9b9882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T07:09:02.914814Z",
     "start_time": "2023-01-23T07:09:02.909221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastcore.xtras import Path\n",
    "zip_path = Path(\"../data/mnist-png.zip\")\n",
    "zip_path.exists() # Check if the file exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c12f5f6",
   "metadata": {},
   "source": [
    "The data has been persisted to the `mnist-png.zip` file on the local system, within the `../data` directory. The next step is to utilize the `zipfile` package to extract the contents of the archive.\n",
    "\n",
    ":::{.callout-warning}\n",
    "The execution of the following code block will take a significant amount of time(6-10 mins) as it involves the extraction of 70,000 PNG images.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48efd701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T07:26:53.546813Z",
     "start_time": "2023-01-23T07:20:17.810346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Output directory\n",
    "dPath = Path(\"../data/\")\n",
    "\n",
    "# Unzipping data file in output directory\n",
    "import zipfile\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(str(dPath))\n",
    "\n",
    "# Removing the original zip file\n",
    "zip_path.unlink()\n",
    "\n",
    "# Removing duplicate folder in the unzipped data\n",
    "import shutil\n",
    "dPath = dPath/'mnist_png'\n",
    "shutil.rmtree(dPath/'mnist_png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a22cf0",
   "metadata": {},
   "source": [
    "Next, we inspect the extracted folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d90b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:44:59.458399Z",
     "start_time": "2023-01-24T05:44:59.451705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('../data/mnist_png/testing'),Path('../data/mnist_png/training')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dPath.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7072b0",
   "metadata": {},
   "source": [
    "Data contains of two folder `training` and `testing`. Next, we inspect `training` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01ef9d96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:00.248286Z",
     "start_time": "2023-01-24T05:45:00.243566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('../data/mnist_png/training/0'),Path('../data/mnist_png/training/1'),Path('../data/mnist_png/training/2'),Path('../data/mnist_png/training/3'),Path('../data/mnist_png/training/4'),Path('../data/mnist_png/training/5'),Path('../data/mnist_png/training/6'),Path('../data/mnist_png/training/7'),Path('../data/mnist_png/training/8'),Path('../data/mnist_png/training/9')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dPath/'training').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c922f568",
   "metadata": {},
   "source": [
    "The `training` folder comprises of subfolders for each digit ranging from `0` to `9`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c5d5f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:01.964031Z",
     "start_time": "2023-01-24T05:45:01.926482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5923) [Path('../data/mnist_png/training/0/1.png'),Path('../data/mnist_png/training/0/1000.png'),Path('../data/mnist_png/training/0/10005.png'),Path('../data/mnist_png/training/0/10010.png'),Path('../data/mnist_png/training/0/10022.png'),Path('../data/mnist_png/training/0/10025.png'),Path('../data/mnist_png/training/0/10026.png'),Path('../data/mnist_png/training/0/10045.png'),Path('../data/mnist_png/training/0/10069.png'),Path('../data/mnist_png/training/0/10071.png')...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dPath/'training/0').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e77c08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:54:55.768782Z",
     "start_time": "2023-01-24T05:54:55.765668Z"
    }
   },
   "source": [
    "Each of these digit subfolders contains images. We will proceed to load a few of these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "037e1168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:02.982371Z",
     "start_time": "2023-01-24T05:45:02.878538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAcklEQVR4nGNgGHBg898PiceEKvn/HwNuyRoG3JLSingkI1XxuOfI3/NcuO1k+PUNjyRuO0UFGGbgVOnx950pTp14jWVgYGbBI3nxOE7JcDzGGvswvMdpv//fv454HHTzFh7Jly/xSNo14ZFk+IXTQfQCAPEtF7kcO2nxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAf0lEQVR4nL2RQRLEIAgEZ1P7r5CfsS+Dn00ORGME95i5SdtAKfB+Ps+jYpdUjBgjWjANYqREYZsu+KE/4ILf0XRx72SCcP+7LQCwV+eZgAGtQTZvMZkyiLkpyZqIkv0FClKLDZE2q9Le3CzxrknsZDrAVcMB1gzLL46ZtkJv5wSPVmu45JM5CgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA5klEQVR4nGNgoD9gRGJr+aSevsAw4Rc2demf/v379++fE1ZDhF78+/fv3793blhlM778e/Dv379e7A44/+/Sv3//lLBLhpz79+/fP00cbpe4+O/fv9VwLguyXLSeDgMDw1Fs2jSu/fr3D8VOJoSkpiLEmAKsNuZ9+/cPp52TbgswsEzmw+FYBgYGxoZ/t+VxSbL/+3dNBpdk179/JehiwhujGBgYGBgkP2AJviX/rturMBhHnvv3r5sDXdLy6L9/97Z8/Pfv71VuTLt6Mv/9+/fv3783yIIwf5aw8zAYRDJ8xB7TdAQABFdhZWAfWxoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "for img in [Image.open((dPath/'training/0').ls()[0]), \n",
    "            Image.open((dPath/'training/1').ls()[0]),\n",
    "            Image.open((dPath/'training/2').ls()[0]),\n",
    "            Image.open((dPath/'training/3').ls()[0])]: \n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb8309",
   "metadata": {},
   "source": [
    "## Creating Dataset Object "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8512affe",
   "metadata": {},
   "source": [
    "As previously discussed, prior to training the model, it is necessary to establish a data pipeline in PyTorch. This includes defining a `Dataset` object and subsequently loading it via a PyTorch `Dataloader`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cc0de",
   "metadata": {},
   "source": [
    "### Using Pure Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf1f736",
   "metadata": {},
   "source": [
    "Initially, we will demonstrate the process of constructing a custom image `Dataset` object using pure PyTorch. To begin, we will import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eabb705a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:10.437520Z",
     "start_time": "2023-01-24T05:45:09.414739Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1487815f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T04:06:14.535317Z",
     "start_time": "2023-01-24T04:06:14.532398Z"
    }
   },
   "source": [
    "The `glob` library can be utilized to obtain the filepaths of all images within a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5774094b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:13.027568Z",
     "start_time": "2023-01-24T05:45:12.822235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images count: 60000 \n",
      "Testing images count: 10000\n",
      "['../data/mnist_png/training/0/1.png', '../data/mnist_png/training/0/1000.png', '../data/mnist_png/training/0/10005.png', '../data/mnist_png/training/0/10010.png', '../data/mnist_png/training/0/10022.png']\n"
     ]
    }
   ],
   "source": [
    "train_paths = glob.glob(str(dPath/'training/**/*.png'))\n",
    "test_paths = glob.glob(str(dPath/'testing/**/*.png'))\n",
    "print(f'Training images count: {len(train_paths)} \\nTesting images count: {len(test_paths)}')\n",
    "print(train_paths[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fd2d22",
   "metadata": {},
   "source": [
    "By utilizing `glob`, we have successfully obtained the filepaths of all images within the `training` and `testing` folders. We can see there are 60,000 training images and 10,000 testing images. The next step is to extract the labels from the folder names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48160a32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T06:02:04.130044Z",
     "start_time": "2023-01-24T06:02:04.113784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels count: 60000 \n",
      "Testing labels count: 10000\n",
      "[2 3 8 5 7]\n"
     ]
    }
   ],
   "source": [
    "train_targets = list(map(lambda x: int(x.split('/')[-2]), train_paths))\n",
    "test_targets  = list(map(lambda x: int(x.split('/')[-2]), test_paths))\n",
    "print(f'Training labels count: {len(train_targets)} \\nTesting labels count: {len(test_targets)}')\n",
    "print(np.random.choice(np.array(train_targets),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9966f6",
   "metadata": {},
   "source": [
    "Now let's define our custom image `Dataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ec8b4ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:14.705084Z",
     "start_time": "2023-01-24T05:45:14.702344Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.img_paths = X\n",
    "        self.targets  = y\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_sample = torch.tensor(np.array(Image.open(self.img_paths[idx]))).flatten()/255.\n",
    "        current_target = self.targets[idx]\n",
    "        return (\n",
    "            current_sample, \n",
    "            current_target\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83753e61",
   "metadata": {},
   "source": [
    "As we can see above, `ImageDataset` is a custom PyTorch `Dataset` class. Let's walk through the components - \n",
    "\n",
    "- The class takes two inputs in its constructor, `X` and `y`, which are lists of image file paths and corresponding labels respectively. These are stored as class variables `self.img_paths` and `self.targets`.\n",
    "- The `__len__` method returns the number of images in the dataset by returning the length of `self.img_paths` list.\n",
    "- The `__getitem__` method is called when a specific sample is requested from the dataset. It takes an index as an argument, and returns a tuple of the image data and the corresponding label for that index. The image is processed as follows - \n",
    "    - It opens the image file at the index passed in the argument using PIL(Python Imaging Library) `Image.open` function\n",
    "    - Converts it to a numpy array\n",
    "    - Flattens it (convert it from 28x28 2d array to 784 1-d array)\n",
    "    - Normalizes it by dividing by 255 floating number \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74bd99d",
   "metadata": {},
   "source": [
    "We will now proceed to instantiate our `ImageDataset` class for both the`training` and `testing` datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03f49291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:17.404396Z",
     "start_time": "2023-01-24T05:45:17.374082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One object: Image Tensor of shape torch.Size([784]), Label: 0\n",
      "One object: Image Tensor of shape torch.Size([784]), Label: 3\n"
     ]
    }
   ],
   "source": [
    "train_ds = ImageDataset(X=train_paths, y=train_targets)\n",
    "test_ds = ImageDataset(X=test_paths, y=test_targets)\n",
    "\n",
    "print(f'One object: Image Tensor of shape {train_ds[0][0].shape}, Label: {train_ds[0][1]}')\n",
    "print(f'One object: Image Tensor of shape {train_ds[20000][0].shape}, Label: {train_ds[20000][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebac610",
   "metadata": {},
   "source": [
    "### Using Torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25abed66",
   "metadata": {},
   "source": [
    "Now we have seen how to create a cusomt `ImageDataset` object. Let's see how to simplify this by using the `torchvision` package. The `torchvision` package consists of popular datasets, model architectures, and common image transformations for computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4dd9632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:20.675215Z",
     "start_time": "2023-01-24T05:45:20.542041Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79bdf89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:21.674477Z",
     "start_time": "2023-01-24T05:45:21.434072Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 60000, test_dataset: 10000\n",
      "One object: Image Tensor of shape torch.Size([784]), Label: 0\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda x: torch.flatten(x))\n",
    "    ])\n",
    "\n",
    "## Create a dataset\n",
    "train_ds = datasets.ImageFolder(root = dPath/'training/', \n",
    "                                      transform=transform)\n",
    "\n",
    "test_ds = datasets.ImageFolder(root=dPath/'testing', transform=transform)\n",
    "\n",
    "print(f'Length of train dataset: {len(train_ds)}, test_dataset: {len(test_ds)}')\n",
    "print(f'One object: Image Tensor of shape {train_ds[0][0].shape}, Label: {train_ds[0][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204fa0f3",
   "metadata": {},
   "source": [
    "## Create a Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c73e33",
   "metadata": {},
   "source": [
    "Create a dataloader using `torch.utils.data.DataLoader` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b0313e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:23.961042Z",
     "start_time": "2023-01-24T05:45:23.958508Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "num_workers = int(os.cpu_count()/2)\n",
    "train_dls = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=num_workers)\n",
    "test_dls = torch.utils.data.DataLoader(test_ds, batch_size=128, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42545273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T05:44:51.847585Z",
     "start_time": "2023-01-23T05:44:51.426067Z"
    }
   },
   "source": [
    "Let's look at one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca56c7df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:26.227413Z",
     "start_time": "2023-01-24T05:45:25.194007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 784]),\n",
       " tensor([5, 4, 1, 5, 7, 5, 4, 7, 2, 1, 5, 7, 6, 5, 8, 6, 3, 7, 8, 0, 4, 4, 4, 0,\n",
       "         6, 7, 1, 4, 0, 6, 3, 9, 1, 0, 1, 9, 4, 1, 0, 1, 9, 3, 8, 2, 6, 2, 1, 2,\n",
       "         1, 0, 2, 4, 7, 4, 7, 3, 3, 4, 3, 3, 4, 4, 7, 3, 3, 4, 6, 5, 1, 0, 2, 3,\n",
       "         0, 4, 5, 7, 1, 5, 0, 1, 1, 3, 0, 0, 1, 4, 0, 6, 2, 3, 8, 1, 8, 1, 2, 5,\n",
       "         5, 8, 9, 9, 9, 3, 1, 1, 3, 4, 1, 7, 8, 0, 1, 1, 2, 9, 1, 5, 3, 4, 0, 6,\n",
       "         1, 4, 0, 8, 9, 1, 7, 4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dls))\n",
    "batch[0].shape, batch[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de71542",
   "metadata": {},
   "source": [
    "## Defining our Training and Validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fb28784",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:27.758169Z",
     "start_time": "2023-01-24T05:45:27.754566Z"
    }
   },
   "outputs": [],
   "source": [
    "## Training loop\n",
    "def train_one_epoch(model, data_loader, optimizer, loss_func):\n",
    "    total_loss, nums = 0, 0\n",
    "    for batch in tqdm(iter(data_loader)):\n",
    "        ## Taking one mini-batch\n",
    "        xb, yb = batch[0].to(dev), batch[1].to(dev)\n",
    "        y_pred = model.forward(xb)\n",
    "        \n",
    "        ## Calculation mean square error per min-batch\n",
    "        nums += len(yb)\n",
    "        loss = loss_func(y_pred, yb)\n",
    "        total_loss += loss.item() * len(yb)\n",
    "\n",
    "        ## Computing gradients per mini-batch\n",
    "        loss.backward()\n",
    "        \n",
    "        ## Update model parameters and zero grad\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return  total_loss / nums\n",
    "        \n",
    "def validate_one_epoch(model, data_loader, loss_func):\n",
    "    loss, nums, acc = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(iter(data_loader)):\n",
    "            xb, yb = batch[0].to(dev), batch[1].to(dev)\n",
    "            y_pred = model.forward(xb)\n",
    "            nums += len(yb)\n",
    "            loss += loss_func(y_pred, yb).item() * len(yb)\n",
    "            acc += sum(y_pred.argmax(axis=1) == yb).item()\n",
    "    return loss/nums, acc/nums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864b9e95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T04:34:14.603575Z",
     "start_time": "2023-01-24T04:34:14.601344Z"
    }
   },
   "source": [
    "## Training using a Fully Connected/ Multi Layer Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64c59aad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:30.405209Z",
     "start_time": "2023-01-24T05:45:30.402617Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_in, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_out)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cfdd5e",
   "metadata": {},
   "source": [
    "Let's test our untrained model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c719e90f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:33.361964Z",
     "start_time": "2023-01-24T05:45:32.141944Z"
    }
   },
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "model = MLP(784,10).to(dev)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4da6c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:38.400478Z",
     "start_time": "2023-01-24T05:45:34.726229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf87e70319a640b5a62df1559b40918d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random model: Test Loss: 2.3025, Test Accuracy: 0.0772\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = validate_one_epoch(model=model, data_loader=test_dls, loss_func=loss_func)\n",
    "print(f\"Random model: Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "173eb1d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:45:40.345099Z",
     "start_time": "2023-01-24T05:45:40.342384Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dls, valid_dls):\n",
    "    for epoch in range(5):    \n",
    "        train_loss = train_one_epoch(model=model, data_loader=train_dls, optimizer=optimizer, loss_func=loss_func)\n",
    "        test_loss, test_acc = validate_one_epoch(model=model, data_loader=valid_dls, loss_func=loss_func)\n",
    "        print(f\"Epoch {epoch+1},Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Valid Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b41768f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:47:49.037513Z",
     "start_time": "2023-01-24T05:45:43.514602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5eec6a13d749159ed8425b3527e94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201aa935fe004ac38a76e48d36fc9c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,Train Loss: 2.2945, Test Loss: 2.2852, Valid Accuracy: 0.1614\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb65821ab873440c8a6fdd241aec82d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffc2c4538ea40f7b1581818c848b8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2,Train Loss: 2.2770, Test Loss: 2.2659, Valid Accuracy: 0.2339\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87a36af281041caaa8988942ea31148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796dcb3eccd743c59e90a4f5392ff873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3,Train Loss: 2.2564, Test Loss: 2.2426, Valid Accuracy: 0.3347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f205fd4d9e4df28945ba9ba017387f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a24f7b57b84499a1f0c9d9d30f1c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4,Train Loss: 2.2310, Test Loss: 2.2131, Valid Accuracy: 0.4615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be0806ca9214b798085eea68bc4df21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba2d46c9502427e9350c14fd49114e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5,Train Loss: 2.1983, Test Loss: 2.1752, Valid Accuracy: 0.5695\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, optimizer, train_dls, test_dls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9539bb",
   "metadata": {},
   "source": [
    "Let's train the model now for 5 epochs and we will use `AdamW` optimizer instead of `SGD` from `torch.optim` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25a7836a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:50:29.838438Z",
     "start_time": "2023-01-24T05:48:28.865153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db99533f23c3485b83ca6a6cd7bf93f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eaf45cf702840e6916cbab4b8983d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,Train Loss: 0.3480, Test Loss: 0.1660, Valid Accuracy: 0.9501\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789f236d6f164d19991e6d1fee71a2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560f9859321c4c74b7c410142d70428d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2,Train Loss: 0.1392, Test Loss: 0.1289, Valid Accuracy: 0.9597\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc5d73d71b9401aa59229c282a8d07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff1eb9e523e4901b19532c4ca28b6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3,Train Loss: 0.0895, Test Loss: 0.0931, Valid Accuracy: 0.9699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ac53a559aa48b39e68786360e947bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480ccd0f8e534bcfa9300a1dffa209b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4,Train Loss: 0.0659, Test Loss: 0.0758, Valid Accuracy: 0.9759\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf30719c2b454f8888fd4b6ee3bb7083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ade4489d03463397bbf7f109ae564f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5,Train Loss: 0.0490, Test Loss: 0.0700, Valid Accuracy: 0.9797\n"
     ]
    }
   ],
   "source": [
    "model = MLP(784,10).to(dev)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "fit(epochs, model, loss_func, optimizer, train_dls, test_dls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b1cd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T07:39:14.627859Z",
     "start_time": "2023-01-23T07:39:14.623807Z"
    }
   },
   "source": [
    "We can see after 5 epochs we have a fairly accurate model with 98% accuracy as compared to random prediction of 12%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d398190",
   "metadata": {},
   "source": [
    "## Training using a simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dfdaf82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:50:42.399405Z",
     "start_time": "2023-01-24T05:50:42.395935Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5ce9cd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T05:52:43.227736Z",
     "start_time": "2023-01-24T05:50:43.547646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01ea524e9664e77abc332b6c573d45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368c945206c249e4ae197fa845c02585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,Train Loss: 1.8228, Test Loss: 1.4976, Valid Accuracy: 0.5442\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854ef758af2546979aa757712c3270e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7c1cefbd5e4be2973d2153a730fa05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2,Train Loss: 1.3562, Test Loss: 1.2602, Valid Accuracy: 0.5958\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392814c079304ab1a2aae65045be5330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8014c371ea24de681c8f4e177f5d3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3,Train Loss: 1.2113, Test Loss: 1.1522, Valid Accuracy: 0.6144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43bbc4cf39a4c0bb341aca7739463df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c6871cc6e6418f89dd7d01765716b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4,Train Loss: 1.1286, Test Loss: 1.0886, Valid Accuracy: 0.6187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98da5a25e87b4cb9932449c899393dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f23b1f9907b4245944445f118e76fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5,Train Loss: 1.0741, Test Loss: 1.0454, Valid Accuracy: 0.6308\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_CNN().to(dev)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "fit(epochs, model, loss_func, optimizer, train_dls, test_dls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
