{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a8f73b4",
   "metadata": {},
   "source": [
    "---\n",
    "title: Tensors \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ae7b00",
   "metadata": {},
   "source": [
    "## What are Tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389a6eb",
   "metadata": {},
   "source": [
    "PyTorch provides tensors as its primary data structure. Tensors are similar to numpy arrays, but they can be used on a GPU to accelerate the computation. PyTorch tensors are similar to numpy arrays, but they have additional functionality (automatic differentiation) and are designed to take advantage of GPUs for acceleration. Similar to numpy, tensors in PyTorch supports a variety of operations, including indexing, slicing, math operations, linear algebra operations, and more. Let's dive in by importing the library.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc60886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T19:30:40.998020Z",
     "start_time": "2022-12-26T19:30:40.297313Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1c11ef",
   "metadata": {},
   "source": [
    "## Initializing a Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb58fe3b",
   "metadata": {},
   "source": [
    "There are several ways to initialize tensors in PyTorch. Here are some examples:\n",
    "\n",
    "**Initializing from an iterator like a list**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12b5821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T19:47:03.640369Z",
     "start_time": "2022-12-25T19:47:03.636990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from list: \n",
      " tensor([1, 2, 3, 4])\n",
      "Tensor from nested list: \n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize a tensor from a list\n",
    "tensor_from_list = torch.tensor([1, 2, 3, 4])\n",
    "print(\"Tensor from list: \\n\", tensor_from_list)\n",
    "\n",
    "# Initialize a tensor from a nested list\n",
    "tensor_from_nested_list = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"Tensor from nested list: \\n\", tensor_from_nested_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee97f4f",
   "metadata": {},
   "source": [
    "**Initializing from a numpy array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f0c77e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T19:47:58.479436Z",
     "start_time": "2022-12-25T19:47:58.476329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from np array: \n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Create a NumPy array\n",
    "numpy_array = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "# Initialize a tensor from a NumPy array\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "print(\"Tensor from np array: \\n\", tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c86fc",
   "metadata": {},
   "source": [
    "**Initializing from another tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fab3fae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T19:49:19.939197Z",
     "start_time": "2022-12-25T19:49:19.935406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from another tensor: \n",
      " tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "original_tensor = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "# Initialize a new tensor from the original tensor\n",
    "new_tensor = original_tensor.clone()\n",
    "print(\"Tensor from another tensor: \\n\", new_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612a64f2",
   "metadata": {},
   "source": [
    "**Constant or random initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "647f2944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T19:52:24.593920Z",
     "start_time": "2022-12-25T19:52:24.589406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor with all elements set to zero: \n",
      " tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "\n",
      " Tensor with all elements set to one: \n",
      " tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "\n",
      " Tensor with all elements set to a specific value: \n",
      " tensor([[2.5000, 2.5000, 2.5000, 2.5000],\n",
      "        [2.5000, 2.5000, 2.5000, 2.5000],\n",
      "        [2.5000, 2.5000, 2.5000, 2.5000]])\n",
      "\n",
      " Tensor with random initialization: \n",
      " tensor([[0.8675, 0.0161, 0.5472, 0.7002],\n",
      "        [0.6551, 0.3049, 0.4088, 0.6341],\n",
      "        [0.2363, 0.8951, 0.0335, 0.5779]])\n",
      "\n",
      " Tensor with random values from a normal distribution: \n",
      " tensor([[ 1.0550,  0.9214, -1.3023,  0.4119],\n",
      "        [-0.4691,  0.8733,  0.7910, -2.3932],\n",
      "        [-0.6304, -0.8792,  0.4188,  0.4221]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize a tensor with all elements set to zero\n",
    "tensor_zeros = torch.zeros(3, 4)\n",
    "print(\"Tensor with all elements set to zero: \\n\", tensor_zeros)\n",
    "\n",
    "# Initialize a tensor with all elements set to one\n",
    "tensor_ones = torch.ones(3, 4)\n",
    "print(\"\\n Tensor with all elements set to one: \\n\", tensor_ones)\n",
    "\n",
    "# Initialize a tensor with all elements set to a specific value\n",
    "tensor_full = torch.full((3, 4), fill_value=2.5)\n",
    "print(\"\\n Tensor with all elements set to a specific value: \\n\", tensor_full)\n",
    "\n",
    "# Initialize a tensor with random values\n",
    "tensor_rand = torch.rand(3, 4)\n",
    "print(\"\\n Tensor with random initialization: \\n\", tensor_rand)\n",
    "\n",
    "# Initialize a tensor with random values from a normal distribution\n",
    "tensor_randn = torch.randn(3, 4)\n",
    "print(\"\\n Tensor with random values from a normal distribution: \\n\", tensor_randn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac530a2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T20:27:01.354104Z",
     "start_time": "2022-12-25T20:27:01.351064Z"
    }
   },
   "source": [
    "## Tensor Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d1b42",
   "metadata": {},
   "source": [
    "It has several attributes that you can access to get information about the tensor. Here are some common attributes of a PyTorch tensor:\n",
    "\n",
    "- `shape`: returns the shape of the tensor as a tuple of integers. For example, if the tensor has dimensions (batch_size, num_channels, height, width), the shape would be (batch_size, num_channels, height, width).\n",
    "- `dtype`: returns the data type of the tensor. For example, the data type could be torch.float32 or torch.int64.\n",
    "- `device`: returns the device on which the tensor is stored. This can be the CPU or a GPU.\n",
    "- `requires_grad`: a boolean flag indicating whether the tensor requires gradient computation. If set to True, the tensor's gradients will be computed during backpropagation.\n",
    "- `grad`: a tensor containing the gradient of the tensor with respect to some scalar value. This attribute is typically used during training with gradient descent.\n",
    "\n",
    "You can access these attributes by calling them on a tensor object. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e1ca957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T20:40:38.985981Z",
     "start_time": "2022-12-25T20:40:38.982978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor : torch.Size([3, 4])\n",
      "Type of tensor : torch.float32\n",
      "Device tensor is stored on : cpu\n",
      "Autograd enabled : False\n",
      "Any stored gradient : None\n"
     ]
    }
   ],
   "source": [
    "tensor_randn = torch.randn(3, 4)\n",
    "print(f\"Shape of tensor : {tensor_randn.shape}\")\n",
    "print(f\"Type of tensor : {tensor_randn.dtype}\")\n",
    "print(f\"Device tensor is stored on : {tensor_randn.device}\")\n",
    "print(f\"Autograd enabled : {tensor_randn.requires_grad}\")\n",
    "print(f\"Any stored gradient : {tensor_randn.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c0e6a",
   "metadata": {},
   "source": [
    "As we can see above we initialized a random tensor of shape (3,4) with a torch.float32 data type and its currently on a cpu device. Currently, automatic gradient calculations are disabled and no gradient is stored in the tensor. \n",
    "\n",
    "There are several other attributes that you can access, such as `ndim`, `size`, `numel`, `storage`, etc. You can find more information about these attributes in the [PyTorch Tensor documentation](https://pytorch.org/docs/stable/tensors.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641efc40",
   "metadata": {},
   "source": [
    "## Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d235d9",
   "metadata": {},
   "source": [
    "There are several operations you can perform on tensors, lets look at the most commonly used operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ed3e1",
   "metadata": {},
   "source": [
    "### Moving tensor from CPU to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decfcfe9",
   "metadata": {},
   "source": [
    "To move a tensor from CPU to GPU is a simple command but probably the one which people will use the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a272d0a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T22:34:30.481106Z",
     "start_time": "2022-12-25T22:34:30.457389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0984, -1.3804,  0.3343, -0.1623],\n",
       "        [ 0.9155, -0.8620, -0.3943, -0.2997],\n",
       "        [-0.1336, -0.7395, -0.7143, -0.0735]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_randn.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d33f87c",
   "metadata": {},
   "source": [
    "As we can see the tensor_randn is now moved to a cuda(GPU) device."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f858f5",
   "metadata": {},
   "source": [
    "### Slicing and Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c9aeb",
   "metadata": {},
   "source": [
    "PyTorch tensors similar to numpy arrays support various slicing and indexing operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b536a2e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T22:43:25.713911Z",
     "start_time": "2022-12-25T22:43:25.709184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3470,  0.2204,  0.2963, -0.9745],\n",
       "        [ 0.1867, -1.8338, -1.1872, -1.2987],\n",
       "        [ 0.0517, -0.3206,  0.3584, -0.4778]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_randn = torch.randn(3, 4)\n",
    "tensor_randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e11c0005",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T22:43:26.415622Z",
     "start_time": "2022-12-25T22:43:26.411369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:  \n",
      "tensor([-1.3470,  0.2204,  0.2963, -0.9745])\n",
      "\n",
      " First column: \n",
      " tensor([-1.3470,  0.1867,  0.0517])\n",
      "\n",
      " Last column: tensor([-0.9745, -1.2987, -0.4778])\n",
      "\n",
      " Selected columns: \n",
      " tensor([[ 0.2963, -0.9745],\n",
      "        [-1.1872, -1.2987],\n",
      "        [ 0.3584, -0.4778]])\n",
      "\n",
      " Assigning column to zero: \n",
      " tensor([[-1.3470,  0.0000,  0.2963, -0.9745],\n",
      "        [ 0.1867,  0.0000, -1.1872, -1.2987],\n",
      "        [ 0.0517,  0.0000,  0.3584, -0.4778]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"First row:  \\n{tensor_randn[0]}\")\n",
    "print(f\"\\n First column: \\n {tensor_randn[:, 0]}\")\n",
    "print(f\"\\n Last column: {tensor_randn[..., -1]}\")\n",
    "print(f\"\\n Selected columns: \\n {tensor_randn[:,2:4]}\")\n",
    "## Assignment of column to zero\n",
    "tensor_randn[:,1] = 0\n",
    "print(\"\\n Assigning column to zero: \\n\", tensor_randn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d0956",
   "metadata": {},
   "source": [
    "### Concatenation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c01779",
   "metadata": {},
   "source": [
    "The `torch.cat` function can be used to concatenate or join multiple tensors together, which is often useful when working with deep learning models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d756f51",
   "metadata": {},
   "source": [
    "Let's take our previous defined tensors and check their shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1e6e208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T22:51:05.329440Z",
     "start_time": "2022-12-25T22:51:05.326348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.Size([3, 4]), torch.Size([3, 4]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_ones.shape, tensor_zeros.shape, tensor_rand.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0302953",
   "metadata": {},
   "source": [
    "We can concatenate these tensors  column wise by using `torch.cat` with `dim=1`. We will get a resultant tensor with shape (3,12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bec6a90f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T22:51:30.836022Z",
     "start_time": "2022-12-25T22:51:30.831533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8675,\n",
       "         0.0161, 0.5472, 0.7002],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6551,\n",
       "         0.3049, 0.4088, 0.6341],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2363,\n",
       "         0.8951, 0.0335, 0.5779]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_tensor = torch.cat([tensor_ones, tensor_zeros, tensor_rand], dim=1)\n",
    "print(concat_tensor.shape)\n",
    "concat_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa640d6",
   "metadata": {},
   "source": [
    "We can concatenate these tensors  row wise by using `torch.cat` with `dim=0`. We will get a resultant tensor with shape (9,4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62205899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T22:51:40.750201Z",
     "start_time": "2022-12-25T22:51:40.746284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8675, 0.0161, 0.5472, 0.7002],\n",
       "        [0.6551, 0.3049, 0.4088, 0.6341],\n",
       "        [0.2363, 0.8951, 0.0335, 0.5779]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_tensor = torch.cat([tensor_ones, tensor_zeros, tensor_rand], dim=0)\n",
    "print(concat_tensor.shape)\n",
    "concat_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754308a7",
   "metadata": {},
   "source": [
    "### Arithmetic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3771f6",
   "metadata": {},
   "source": [
    "In PyTorch, you can perform arithmetic operations on tensors in a similar way to how you would perform them on numpy arrays. Lets look at some common arithmetic operations - \n",
    "\n",
    "**Element wise addition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4042d90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T19:38:04.682966Z",
     "start_time": "2022-12-26T19:38:04.679197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 1: \n",
      " tensor([[-0.4685, -0.7848, -0.4198,  0.0890],\n",
      "        [ 0.2496,  0.2578,  0.6366, -2.0815],\n",
      "        [-1.6914, -0.8824,  1.0809,  1.5308]])\n",
      "\n",
      " Tensor 2: \n",
      " tensor([[-0.3125,  1.0860,  0.7340,  0.2249],\n",
      "        [-0.9887,  0.2265, -0.5214, -1.5676],\n",
      "        [ 0.6817,  0.1099, -0.5298, -0.3109]])\n",
      "\n",
      " Tensor additions using + : \n",
      " tensor([[-0.7810,  0.3013,  0.3142,  0.3139],\n",
      "        [-0.7391,  0.4843,  0.1152, -3.6492],\n",
      "        [-1.0097, -0.7725,  0.5511,  1.2199]])\n",
      "\n",
      " Tensor additions using .add : \n",
      " tensor([[-0.7810,  0.3013,  0.3142,  0.3139],\n",
      "        [-0.7391,  0.4843,  0.1152, -3.6492],\n",
      "        [-1.0097, -0.7725,  0.5511,  1.2199]])\n"
     ]
    }
   ],
   "source": [
    "tnsr1 = torch.randn((3,4))\n",
    "print(f\"Tensor 1: \\n\", tnsr1)\n",
    "tnsr2 = torch.randn((3,4))\n",
    "print(f\"\\n Tensor 2: \\n\", tnsr2)\n",
    "\n",
    "## Addition\n",
    "tensor_add = tnsr1 + tnsr2 \n",
    "print(f\"\\n Tensor additions using + : \\n\", tensor_add)\n",
    "\n",
    "tensor_add = tnsr1.add(tnsr2)\n",
    "print(f\"\\n Tensor additions using .add : \\n\", tensor_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab835baf",
   "metadata": {},
   "source": [
    "**Element wise subtraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0a533e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T19:39:32.241459Z",
     "start_time": "2022-12-26T19:39:32.238300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tensor subtraction using - : \n",
      " tensor([[-0.1561, -1.8708, -1.1537, -0.1359],\n",
      "        [ 1.2384,  0.0313,  1.1580, -0.5139],\n",
      "        [-2.3732, -0.9923,  1.6107,  1.8417]])\n",
      "\n",
      " Tensor subtraction using .sub : \n",
      " tensor([[-0.1561, -1.8708, -1.1537, -0.1359],\n",
      "        [ 1.2384,  0.0313,  1.1580, -0.5139],\n",
      "        [-2.3732, -0.9923,  1.6107,  1.8417]])\n"
     ]
    }
   ],
   "source": [
    "## Subtraction\n",
    "tensor_sub = tnsr1 - tnsr2 \n",
    "print(f\"\\n Tensor subtraction using - : \\n\", tensor_sub)\n",
    "\n",
    "tensor_sub = tnsr1.sub(tnsr2)\n",
    "print(f\"\\n Tensor subtraction using .sub : \\n\", tensor_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f94c541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T19:38:42.197520Z",
     "start_time": "2022-12-26T19:38:42.194570Z"
    }
   },
   "source": [
    "**Element wise multiplication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4191fb8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T19:39:25.561507Z",
     "start_time": "2022-12-26T19:39:25.558061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tensor element-wise multiplication using * : \n",
      " tensor([[ 0.1464, -0.8523, -0.3081,  0.0200],\n",
      "        [-0.2468,  0.0584, -0.3319,  3.2631],\n",
      "        [-1.1531, -0.0970, -0.5727, -0.4759]])\n",
      "\n",
      " Tensor element-wise multiplication using .mul : \n",
      " tensor([[ 0.1464, -0.8523, -0.3081,  0.0200],\n",
      "        [-0.2468,  0.0584, -0.3319,  3.2631],\n",
      "        [-1.1531, -0.0970, -0.5727, -0.4759]])\n"
     ]
    }
   ],
   "source": [
    "## Multiplication\n",
    "tensor_mul = tnsr1 * tnsr2 \n",
    "print(f\"\\n Tensor element-wise multiplication using * : \\n\", tensor_mul)\n",
    "\n",
    "tensor_mul = tnsr1.mul(tnsr2)\n",
    "print(f\"\\n Tensor element-wise multiplication using .mul : \\n\", tensor_mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aa5c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T19:39:01.772983Z",
     "start_time": "2022-12-26T19:39:01.770041Z"
    }
   },
   "source": [
    "**Element wise division**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "536cfa9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T19:39:14.825458Z",
     "start_time": "2022-12-26T19:39:14.822102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tensor element-wise division using + : \n",
      " tensor([[ 1.4994, -0.7226, -0.5719,  0.3958],\n",
      "        [-0.2525,  1.1381, -1.2209,  1.3278],\n",
      "        [-2.4811, -8.0272, -2.0401, -4.9238]])\n",
      "\n",
      " Tensor element-wise division using .div : \n",
      " tensor([[ 1.4994, -0.7226, -0.5719,  0.3958],\n",
      "        [-0.2525,  1.1381, -1.2209,  1.3278],\n",
      "        [-2.4811, -8.0272, -2.0401, -4.9238]])\n"
     ]
    }
   ],
   "source": [
    "## Division\n",
    "tensor_div = tnsr1 / tnsr2 \n",
    "print(f\"\\n Tensor element-wise division using / : \\n\", tensor_div)\n",
    "\n",
    "tensor_div = tnsr1.div(tnsr2)\n",
    "print(f\"\\n Tensor element-wise division using .div : \\n\", tensor_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a4fd68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T19:40:19.448176Z",
     "start_time": "2022-12-26T19:40:19.445391Z"
    }
   },
   "source": [
    "**Matrix multiplication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "682b15ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T19:43:42.844471Z",
     "start_time": "2022-12-26T19:43:42.841076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tensor matrix multiplication using @: \n",
      " tensor([[-0.9940,  0.3648, -0.2109],\n",
      "        [ 0.2010,  2.7427,  0.5084],\n",
      "        [ 0.7078, -1.4908, -2.2987]])\n",
      "\n",
      " Tensor matrix multiplication using .matmul: \n",
      " tensor([[-0.9940,  0.3648, -0.2109],\n",
      "        [ 0.2010,  2.7427,  0.5084],\n",
      "        [ 0.7078, -1.4908, -2.2987]])\n"
     ]
    }
   ],
   "source": [
    "tensor_mm = tnsr1 @ tnsr2.T\n",
    "print(f\"\\n Tensor matrix multiplication using @: \\n\", tensor_mm)\n",
    "\n",
    "tensor_mm = tnsr1.matmul(tnsr2.T)\n",
    "print(f\"\\n Tensor matrix multiplication using .matmul: \\n\", tensor_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c518a",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "Observe that `tnsr1` and `tnsr2` have shape (3,4). To perform a matrix multiplication, we used the `.T` function to transpose `tnsr2`, which changed its shape to (4,3). The resulting matrix multiplication has size (3x3).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8a8d8a",
   "metadata": {},
   "source": [
    "**Summing it up**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f150cdf6",
   "metadata": {},
   "source": [
    "Summing tensors along rows and columns is a common operation. Here is the syntax for this operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e98036f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T20:00:29.283615Z",
     "start_time": "2022-12-26T20:00:29.280282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      " tensor([[-0.4685, -0.7848, -0.4198,  0.0890],\n",
      "        [ 0.2496,  0.2578,  0.6366, -2.0815],\n",
      "        [-1.6914, -0.8824,  1.0809,  1.5308]])\n",
      "\n",
      " All up sum: \n",
      " -2.48371958732605\n",
      "\n",
      " Column wise sum: \n",
      " tensor([-1.9103, -1.4094,  1.2977, -0.4617])\n",
      "\n",
      " Row wise sum: \n",
      " tensor([-1.5841, -0.9375,  0.0378])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor: \\n {tnsr1}\" )\n",
    "print(f\"\\n All up sum: \\n {tnsr1.sum()}\")\n",
    "print(f\"\\n Column wise sum: \\n {tnsr1.sum(0)}\")\n",
    "print(f\"\\n Row wise sum: \\n {tnsr1.sum(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302e9173",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef87ae0",
   "metadata": {},
   "source": [
    "- [Pytorch tensors tutorial documentation](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
