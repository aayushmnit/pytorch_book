{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c7bbedb",
   "metadata": {},
   "source": [
    "---\n",
    "title: Defining Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fd4cb4",
   "metadata": {},
   "source": [
    "## Introduction to the `torch.nn` module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3332b6f3",
   "metadata": {},
   "source": [
    "So far, we have explored various components of Pytorch, such as tensor manipulation, data loading, and parameter optimization. In this chapter, we will delve further into Pytorch by learning about the `torch.nn` module, which is designed for building and training machine learning models, particularly neural networks. The `torch.nn` module has a simple and pythonic API that makes it easy to prototype and create complex models with just a few lines of code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a953c23c",
   "metadata": {},
   "source": [
    "## Exercise: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b3123c",
   "metadata": {},
   "source": [
    "To continue our example of linear regression, we will now see how to use the `torch.nn` module to replace our custom model class. Before we do that, we will first generate a random linear dataset with four features and split the data into training and testing sets. Then, we will create custom Dataset and DataLoader objects to load the training and testing data in mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dff5cd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T07:03:08.335362Z",
     "start_time": "2023-01-20T07:03:07.791600Z"
    }
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "## Importing required functions\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Generate dataset with linear property\n",
    "X, y, coef = make_regression(\n",
    "    n_samples=1500,\n",
    "    n_features=4,  ## Using four features\n",
    "    n_informative=4,\n",
    "    noise=0.3,\n",
    "    coef=True,\n",
    "    random_state=0,\n",
    "    bias=2)\n",
    "\n",
    "\n",
    "## Creating our custom TabularDataset\n",
    "class TabularDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_sample = self.data[idx]\n",
    "        current_target = self.targets[idx]\n",
    "        return {\n",
    "            \"X\": torch.tensor(current_sample, dtype=torch.float),\n",
    "            \"y\": torch.tensor(current_target, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "\n",
    "## Making a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "## Creating Tabular Dataset\n",
    "train_dataset = TabularDataset(X_train, y_train)\n",
    "test_dataset = TabularDataset(X_test, y_test)\n",
    "\n",
    "## Creating Dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "## Training loop\n",
    "def train_one_epoch(model, data_loader, optimizer):\n",
    "    for batch in iter(data_loader):\n",
    "        ## Taking one mini-batch\n",
    "        y_pred = model.forward(batch['X']).squeeze()\n",
    "        y_true = batch['y']\n",
    "        \n",
    "        ## Calculation mean square error per min-batch\n",
    "        loss = torch.square(y_pred - y_true).sum()\n",
    "    \n",
    "        ## Computing gradients per mini-batch\n",
    "        loss.backward()\n",
    "        \n",
    "        ## Update model parameters and zero grad\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "## Validation loop\n",
    "def validate_one_epoch(model, data_loader, optimizer):\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iter(data_loader):\n",
    "            y_pred = model.forward(batch['X']).squeeze()\n",
    "            y_true = batch['y']\n",
    "            loss += torch.square(y_pred- y_true).sum()\n",
    "    return loss/len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26938e2a",
   "metadata": {},
   "source": [
    "The `torch.nn` module contains several predefined layers that can be used to create neural networks. These layers can be found in the official PyTorch documentation for the [torch.nn module](https://pytorch.org/docs/stable/nn.html). By using these predefined layers, we can simplify the process of building and training our model, as we don't have to worry about implementing the details of each layer ourselves. Instead, we can simply specify the layers we want to use and let PyTorch handle the rest.\n",
    "\n",
    "Now let's rewrite the model class using `torch.nn` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e1d7c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T07:03:19.047430Z",
     "start_time": "2023-01-20T07:03:19.038864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \n",
      "Linear(\n",
      "  (linear): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "Weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.4191,  0.2242, -0.1830,  0.0542]], requires_grad=True)\n",
      "Bias\n",
      "Parameter containing:\n",
      "tensor([0.4944], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class Linear(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(n_in, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "## Initializing model\n",
    "model = Linear(X.shape[1], 1)\n",
    "print(f\"Model: \\n{model}\")\n",
    "\n",
    "print(f\"Weights\")\n",
    "print(list(model.parameters())[0])\n",
    "\n",
    "print(f\"Bias\")\n",
    "print(list(model.parameters())[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc0f68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-08T19:26:36.850659Z",
     "start_time": "2023-01-08T19:26:36.847366Z"
    }
   },
   "source": [
    "The code above defines a class called `Linear` which extends the functionality of the `nn.Module` class from PyTorch's `torch.nn` module. The Linear class has two methods: `__init__` and `forward`.\n",
    "\n",
    "- The ` __init__` method is the constructor for the class. It takes two arguments: `n_in` and `n_out`, which represent the number of input and output features, respectively. The method initializes the parent class using `super().__init__()` and then creates a linear layer using [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html). This layer will have `n_in` input features and `n_out` output features.\n",
    "- The `forward` method takes an input tensor `x` and applies the linear layer to it, returning the result.\n",
    "\n",
    "After the `Linear` class is defined, an instance of the class is created and assigned to the `model` variable. The `model` object has two learnable parameters: the weights and the bias of the linear layer. These parameters can be accessed using the `parameters` method and indexed using square brackets. The weights are the first element in the list of parameters, and the bias is the second element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd244a1",
   "metadata": {},
   "source": [
    "Now letâ€™s run through some epochs and train our model. We are using the same `optimizer`,  `train_one_epoch`, and `validate_one_epoch` from the last chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65b3cd45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T07:03:23.612689Z",
     "start_time": "2023-01-20T07:03:23.398806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0,Train MSE: 14168.0879 Test MSE: 16699.098\n",
      "Epoch 1,Train MSE: 285.8107 Test MSE: 347.672\n",
      "Epoch 2,Train MSE: 11.2080 Test MSE: 13.391\n",
      "Epoch 3,Train MSE: 5.7762 Test MSE: 5.876\n",
      "Epoch 4,Train MSE: 5.6652 Test MSE: 5.653\n",
      "Epoch 5,Train MSE: 5.6483 Test MSE: 5.556\n",
      "Epoch 6,Train MSE: 5.6559 Test MSE: 5.576\n",
      "Epoch 7,Train MSE: 5.6767 Test MSE: 5.539\n",
      "Epoch 8,Train MSE: 5.6488 Test MSE: 5.557\n",
      "Epoch 9,Train MSE: 5.6495 Test MSE: 5.552\n",
      "Actual coefficients are: \n",
      "[63.0061 44.1452 84.3648  9.3378] \n",
      "Trained model weights are: \n",
      "[62.9917 44.1615 84.3643  9.3292]\n",
      "Actual Bias term is 2 \n",
      "Trained model bias term is \n",
      "1.9978\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "for epoch in range(10):    \n",
    "    # run one training loop\n",
    "    train_one_epoch(model, train_dataloader, optimizer)\n",
    "    # run validation loop on training to compute training loss\n",
    "    train_loss = validate_one_epoch(model, train_dataloader, optimizer)\n",
    "    # run validation loop on testing to compute test loss\n",
    "    test_loss = validate_one_epoch(model, test_dataloader, optimizer)\n",
    "    \n",
    "    print(f\"Epoch {epoch},Train MSE: {train_loss:.4f} Test MSE: {test_loss:.3f}\")\n",
    "    \n",
    "print(f\"Actual coefficients are: \\n{np.round(coef,4)} \\nTrained model weights are: \\n{np.round(list(model.parameters())[0].detach().numpy()[0],4)}\")\n",
    "print(f\"Actual Bias term is {2} \\nTrained model bias term is \\n{list(model.parameters())[1].detach().numpy()[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f80641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-08T19:42:46.161506Z",
     "start_time": "2023-01-08T19:42:46.158614Z"
    }
   },
   "source": [
    "As shown above, our model has fit the data well, just like the last chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c86af",
   "metadata": {},
   "source": [
    "## Saving and Loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc11f13",
   "metadata": {},
   "source": [
    "If we want to save only the learned parameters from the model, we can use `torch.save(model.state_dict())` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42217fdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T07:03:33.002791Z",
     "start_time": "2023-01-20T07:03:32.998582Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"../models/linear_model.pt\"\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156141ec",
   "metadata": {},
   "source": [
    "To reload the saved parameters, we first need to initiate the model object and feed the saved model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5545c9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T07:03:39.570150Z",
     "start_time": "2023-01-20T07:03:39.563807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights are: \n",
      "[62.9917 44.1615 84.3643  9.3292]\n",
      "\n",
      "Loaded model bias term is \n",
      "1.9978\n"
     ]
    }
   ],
   "source": [
    "model_new = Linear(X.shape[1], 1)\n",
    "model_new.load_state_dict(torch.load(path))\n",
    "print(f\"Loaded model weights are: \\n{np.round(list(model_new.parameters())[0].detach().numpy()[0],4)}\")\n",
    "print(f\"\\nLoaded model bias term is \\n{list(model_new.parameters())[1].detach().numpy()[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a54f5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-08T19:48:56.477886Z",
     "start_time": "2023-01-08T19:48:56.475931Z"
    }
   },
   "source": [
    "## Exercise: What is torch.nn really?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e7354c",
   "metadata": {},
   "source": [
    "Now that we have a good understanding of the fundamental concepts of Pytorch, I highly recommend reading the tutorial by Jeremy Howard from [fast.ai](https://www.fast.ai/) titled [\"WHAT IS TORCH.NN REALLY?\"](https://pytorch.org/tutorials/beginner/nn_tutorial.html). This tutorial covers everything we have learned so far and goes into more depth on the `torch.nn` module by showing how to implement it from scratch. It also introduces a new design pattern for building models using the `nn.Sequential` object, which allows you to define a model as a sequential chain of different layers. This is a simpler way of creating neural networks compared to writing them from scratch using the `nn.Module` class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23839749",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985b578",
   "metadata": {},
   "source": [
    "- [WHAT IS TORCH.NN REALLY?](https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
    "- [Pytorch Tutorial - Build model](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n",
    "- [Pytorch torch.nn module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
